{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ripgrepy\n",
    "!apt install ripgrep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_df.to_csv('your.csv', index=False) # don't write unnamed: 0 index col\n",
    "# tmp_df.read_csv('your.csv', index_col=0) #or if did, tell pandas to use 1st col as index\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "filepath = Path('nogit_data', 'list_of_post_contents.csv')\n",
    "#df = pd.read_csv(filepath, nrows=10_00)\n",
    "df = pd.read_csv(filepath).dropna(subset='time_downloaded')\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.post_ordinal.apply(type).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_types = df.post_ordinal.apply(type).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comma_to_int(df, col_name):\n",
    "    df[col_name] = df[col_name].apply(lambda x: x.replace(',', '') if type(x) == str else x) \n",
    "    df[col_name] = df[col_name].astype(float)\n",
    "    df[col_name] = df[col_name].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.post_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-id is unique -- we can use it to drop duplicate downloads of posts\n",
    "\n",
    "filepath = Path('nogit_data', 'list_of_post_contents.csv')\n",
    "#df = pd.read_csv(filepath, nrows=10_00)\n",
    "df = pd.read_csv(filepath)\n",
    "df = df.dropna(subset='time_downloaded')\n",
    "df = df.drop_duplicates('post_id')\n",
    "df.to_csv('nogit_data/list_of_post_contents_nona.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to covnert join date data to datetime pandas\n",
    "# how to time runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['join_date_data', 'join_date_readable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "#\n",
    "df.join_date_data.parallel_apply(lambda x: pd.to_datetime(x, unit = 's'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.join_date_readable.parallel_apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column values like \"2.0\" to \"2\" and \"2,000\" to \"2000\" (as integers)\n",
    "df = pd.read_csv('nogit_data/list_of_post_contents_nona.csv')\n",
    "for column in ['post_ordinal', 'author_num_posts', 'thread_page_num', 'thread_max_pages', 'num_quotes']:\n",
    "    print(column)\n",
    "    df = comma_to_int(df, column)\n",
    "\n",
    "df.to_csv('nogit_data/list_of_post_contents_nona_nocomma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nogit_data/list_of_post_contents_nona_nocomma.csv')\n",
    "df.drop(columns=['comment', 'join_date_data', 'posted_date_data'], inplace=True)\n",
    "df.to_csv('nogit_data/list_of_post_contents_nona_nocomma_nodate.csv', index=False)\n",
    "df.drop(columns=['num_likers'], inplace=True)\n",
    "df.to_csv('nogit_data/list_of_post_contents_nona_nocomma_nodate_nonumlikers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('nogit_data/list_of_post_contents_nona_nocomma_nodate_nonumlikers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readable = ['author', 'posted_date_readable', 'src_category_name', 'thread_page_url', 'post_ordinal', 'post_text']\n",
    "\n",
    "df[readable].to_csv('nogit_data/post_data_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df.post_id=='post-874660'].thread_page_url.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 100, 'display.max_columns', 30):\n",
    "    display(df[df.duplicated(subset=['post_ordinal', 'post_id', 'post_text'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(subset=['post_text'])#, inplace=True) --> mostly, having only quoted text as a post\n",
    "print(f'{df.shape=}')\n",
    "df.drop_duplicates(subset=['author', 'post_text'])#, inplace=True)\n",
    "print(f'{df.shape=}')\n",
    "print(f'{df.shape=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop_duplicates().info()\n",
    "#df.groupby(df.columns.tolist(),as_index=False).first().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df.post_text == null ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    unique_types = df[col].apply(type).unique()\n",
    "    if len(unique_types) > 1:\n",
    "        print(col, unique_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix string columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.post_text.isna()].iloc[0].post_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['post_text'] = df['post_text'].fillna('')#, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.post_text.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.post_text=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[readable].to_csv('nogit_data/post_data_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ripgrepy import Ripgrepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = Ripgrepy('undercover', str(Path('nogit_data', 'post_data_only.csv')))\n",
    "rg.before_context(2).pretty().run()#.as_string\n",
    "rg = Ripgrepy('undercover', str(Path('nogit_data', 'post_data_only.csv')))\n",
    "rg.count_matches().pretty().run()#.as_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rg \"undercover\" nogit_data/post_data_only.csv --count-matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = Ripgrepy('undercover', str(Path('nogit_data', 'post_data_only.csv')))\n",
    "rg.stats().pretty().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date downloaded - author - author url - post \n",
    "readable = ['time_downloaded', 'posted_date_readable', 'src_category_name','thread_page_url', 'author', 'author_url', 'post_text' ]\n",
    "df[readable].to_csv('nogit_data/hackathon_ripgrep_post_contents.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv('nogit_data/hackathon_ripgrep_post_contents.csv')\n",
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import base64\n",
    "from pandas.util import hash_pandas_object\n",
    "\n",
    "print(df.columns)\n",
    "all_authors = pd.Series(df.author.unique())\n",
    "    # author_re = re.compile('|'.join(re.escape(a) for a in all_authors))\n",
    "\n",
    "    author_ids = {a: base64.b64encode(a.to_bytes(8, 'big')) for a in hash_pandas_object(all_authors)}\n",
    "    print(author_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('v3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "47339dd7c6d4bd32b6c40d54a37ff47f789dc7ff328ffb1f4a95f19daef7217e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
