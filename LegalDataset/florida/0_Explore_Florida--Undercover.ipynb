{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29 Mar 2023\n",
    "# nrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Dataset description\n",
    "# -- Graph # of cases vs month over last 10 years\n",
    "\n",
    "# POSSIBLE Case studies:\n",
    "# (See if anything interesting comes up...)\n",
    "\n",
    "# 1. How was use of 'undercover' changed over time\n",
    "# -- graph by every month for 10 years\n",
    "# -- in both absolute counts and % counts of total cases\n",
    "# -- Probably need to avoid coutning multiple times by using the case id?\n",
    "\n",
    "# 2. How have fines changed over time\n",
    "# -- (Don't divide by type of offense to start)\n",
    "\n",
    "# Would be really cool to see impulse change around the robert kraft case (or\n",
    "# other media news) since that was in florida\n",
    "\n",
    "# -- If time: Could be more interesting to extract type of offense and then see\n",
    "# A. how the ratio has changed over time (NOTE to self: like the extreme poverty split by\n",
    "# region of world graph)\n",
    "# B. how the amount of the fines depends on the type of offense or other\n",
    "# covariates \n",
    "\n",
    "# So many possibilities!!!! Could also auto assign ethnicities by last name,\n",
    "# etc. \n",
    "# Or pull out stats about the sex workers using date of birth etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check which python version running on which computer \n",
    "!which python\n",
    "!uname -n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "#import scipy\n",
    "import calplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Load raw data: \n",
    "cases = pd.read_csv('nogit_data/case_summaries.csv', index_col=0)\n",
    "\n",
    "# -- put text as column in csv \n",
    "files = list( pathlib.Path('nogit_data/text_sample').glob('*.txt'))\n",
    "\n",
    "corpus = {}\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        corpus[file.stem] = ''.join(f.readlines())\n",
    "df_text = pd.DataFrame.from_dict(corpus, orient='index').reset_index()#.columns=['pdf_text']\n",
    "df_text.columns = ['doc_id', 'pdf_text']\n",
    "\n",
    "# -- preproces\n",
    "cases.date = pd.to_datetime(cases['date'])\n",
    "\n",
    "# -- drop duplicate cases (as PDFs will likely include pages of other pdf)\n",
    "# keep oldest case by setting date as the index\n",
    "cases.set_index('date', inplace=True)\n",
    "cases.drop_duplicates(subset='case', keep='first', inplace=True)\n",
    "cases.reset_index(inplace=True)\n",
    "\n",
    "TEST_CASE = 201104833\n",
    "assert cases[cases.case == TEST_CASE].date.dt.year.values == [2012] # should be 2012, not 2013\n",
    "\n",
    "annot_text = pd.merge(left=cases, right=df_text, left_on='doc_id', right_on='doc_id')\n",
    "annot_text.fillna(value={'pdf_text':''}, inplace=True)\n",
    "\n",
    "# - Create features:\n",
    "annot_text['undercover'] = annot_text['pdf_text'].apply(lambda x: 'undercover' in x)\n",
    "\n",
    "# - Plot features:\n",
    "#print(annot_text.columns)\n",
    "#print(annot_text.dtypes)\n",
    "\n",
    "annot_text.set_index('date', inplace=True)\n",
    "annot_text[(annot_text.index > '1990') & (annot_text.index < '2023')].resample('Y').count()\n",
    "_data = annot_text[(annot_text.index > '1990') & (annot_text.index < '2023')].resample('Y').count().reset_index()\n",
    "# -- ?!?! NOTE: altair bar chart is off by one, so \n",
    "# -- manually shift the data  when plotting\n",
    "_data['_year'] = _data.date - pd.DateOffset(years=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars = alt.Chart(_data, title='# of Cases Per Year in Florida', ).mark_bar(size=20).encode(\n",
    "    x=alt.X('_year:T', title='Year'),\n",
    "    #x=alt.X('x:T', axis=alt.Axis(title='Date', format=(\"%b\"), values=data['date'].dt.year.values)),\n",
    "    y=alt.Y('case', title='# of Cases'),\n",
    "    #color='undercover'\n",
    ")\n",
    "\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    dy=-10,\n",
    "    fontSize=15\n",
    ").encode(\n",
    "    text='case')\n",
    "\n",
    "\n",
    "##chart.configure(autosize='fit')\n",
    "(bars + text + bars.mark_point(size=1000, opacity=0.03, tooltip=alt.TooltipContent(\"data\"))).properties(width=30*30).configure_axis(\n",
    "    labelFontSize=20,\n",
    "    titleFontSize=20\n",
    ").configure_title(\n",
    "    fontSize=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('v3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "47339dd7c6d4bd32b6c40d54a37ff47f789dc7ff328ffb1f4a95f19daef7217e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
